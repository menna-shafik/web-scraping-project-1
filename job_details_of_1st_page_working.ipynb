{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4cebbf-1c60-4dd8-9c77-b5854d9d67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc78b4a-8d98-42f6-9099-6f390d9bbb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Open LinkedIn login page\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 10)\n",
    "driver.get(\"https://www.linkedin.com/login\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa94aa9-ccce-4e96-8c9a-0bccc5b1e1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Page 0 contains 25 jobs\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Start scraping jobs\n",
    "with open('linkedin_jobs_with_insights_loop4.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\n",
    "        \"Job Title\", \"Company Name\", \"Job Location\", \"Easy Apply\", \"Job Link\",\n",
    "        \"Insight 1\", \"Insight 2\", \"Insight 3\",\n",
    "        \"Responsibilities\", \"Qualifications\", \"Benefits\", \"Job Summary\"\n",
    "    ])\n",
    "\n",
    "    job_links = []\n",
    "\n",
    "    for start in range(0, 25, 25):\n",
    "        url = f\"https://www.linkedin.com/jobs/search/?keywords=data%20analyst&location=Egypt&start={start}\"\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        for _ in range(5):\n",
    "            driver.find_element(By.TAG_NAME, \"body\").send_keys(Keys.END)\n",
    "            time.sleep(2)\n",
    "\n",
    "        job_blocks = driver.find_elements(By.CLASS_NAME, \"job-card-container\")\n",
    "        print(f\"ðŸ“„ Page {start} contains {len(job_blocks)} jobs\")\n",
    "\n",
    "        for block in job_blocks:\n",
    "            try:\n",
    "                link = block.find_element(By.CSS_SELECTOR, 'a.job-card-container__link').get_attribute(\"href\")\n",
    "                job_links.append(link)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # Move this loop INSIDE the 'with open' block\n",
    "    for job_url in job_links:\n",
    "        driver.get(job_url)\n",
    "        time.sleep(3)\n",
    "\n",
    "        try:\n",
    "            job_title = driver.find_element(By.CSS_SELECTOR, 'h1').text.strip()\n",
    "        except:\n",
    "            job_title = \"N/A\"\n",
    "\n",
    "        try:\n",
    "            company_name = driver.find_element(By.CSS_SELECTOR, 'a.topcard__org-name-link').text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                company_name = driver.find_element(By.CSS_SELECTOR, 'span.topcard__flavor').text.strip()\n",
    "            except:\n",
    "                company_name = \"N/A\"\n",
    "\n",
    "        try:\n",
    "            job_location = driver.find_element(By.CSS_SELECTOR, 'span.topcard__flavor.topcard__flavor--bullet').text.strip()\n",
    "        except:\n",
    "            job_location = \"N/A\"\n",
    "\n",
    "        easy_apply = \"Easy Apply\" if \"Easy Apply\" in driver.page_source else \"Not Available\"\n",
    "\n",
    "        try:\n",
    "            insights_block = driver.find_element(By.XPATH, \"//li[contains(@class, 'job-insight')]\")\n",
    "            insights_texts = insights_block.find_elements(By.XPATH, \".//span[not(contains(@class, 'secondary')) and @dir='ltr'] | .//span[contains(@class, 'secondary')]\")\n",
    "            insight_values = [insight.text.strip() for insight in insights_texts if insight.text.strip()]\n",
    "            while len(insight_values) < 3:\n",
    "                insight_values.append(\"N/A\")\n",
    "        except:\n",
    "            insight_values = [\"N/A\", \"N/A\", \"N/A\"]\n",
    "\n",
    "        try:\n",
    "            jd_container = driver.find_element(By.ID, 'job-details')\n",
    "            jd_html = jd_container.get_attribute(\"innerHTML\")\n",
    "            from bs4 import BeautifulSoup\n",
    "            soup = BeautifulSoup(jd_html, 'html.parser')\n",
    "\n",
    "            def extract_section(header_keywords):\n",
    "                for strong in soup.find_all(['strong', 'h3', 'h4']):\n",
    "                    if any(kw in strong.text.lower() for kw in header_keywords):\n",
    "                        ul = strong.find_parent().find_next('ul')\n",
    "                        if ul:\n",
    "                            return \"\\n\".join(li.text.strip() for li in ul.find_all('li'))\n",
    "                        p = strong.find_parent().find_next('p')\n",
    "                        if p:\n",
    "                            return p.text.strip()\n",
    "                return \"N/A\"\n",
    "\n",
    "            job_summary = soup.text.strip()[:400]\n",
    "            responsibilities = extract_section(['responsibilities', 'tasks', 'role'])\n",
    "            qualifications = extract_section(['qualification', 'requirements', 'skills'])\n",
    "            benefits = extract_section(['benefit', 'perks'])\n",
    "\n",
    "        except Exception as e:\n",
    "            job_summary = responsibilities = qualifications = benefits = \"N/A\"\n",
    "\n",
    "        writer.writerow([\n",
    "            job_title, company_name, job_location, easy_apply, job_url,\n",
    "            insight_values[0], insight_values[1], insight_values[2],\n",
    "            responsibilities, qualifications, benefits, job_summary\n",
    "        ])\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca36c3ab-bb47-4a51-bc1a-c4d9d94f181e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
